{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f50782-6271-48a8-99d4-a9d79f15fbc7",
   "metadata": {},
   "source": [
    "### When using MPLs with multiple hidden layers, input data will be given to the neural network and then complex patterns within the input data are learnt through having multiple hidden layers. While this is good for learning complex patterns within the input layer, it is possible that we might miss the simple patterns within the input data that could have a huge impact in the accuracy of our prediction.\n",
    "\n",
    "## Hence, what we can do is that we can use Functional API in order to generate a concatnate layer before the output layer that will receive the output of the last hidden layer and also the input layer and will fuse them together and gives it to the output layer.\n",
    "\n",
    "#### We will use the california_housing dataset. I will run do the same preprocessing that I did in the regression with MLPs section ( just copy and pasting), and then will use Functional API to build the wide and deep model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02da2a8-f46b-4e1c-b8ef-0c1794259aab",
   "metadata": {},
   "source": [
    "# Within this notebook, the following topics will be discussed:\n",
    "\n",
    "    1- Different instances of wide and deep models \n",
    "    2- Functional APIs \n",
    "    3- Saving and loading models \n",
    "    4- Model checkpoint callback \n",
    "    5- EarlyStopping callback\n",
    "    6- Creating a personal callback method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34741a7a-6531-49e4-a2a7-78fa3e08243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f939d64a-1e29-41e5-9f16-846cce067f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing= fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "538a776e-9696-4e9d-a170-a5470607f828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac0d45f8-45ad-4ccb-9cfb-fd49622ac80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0,X_test, y_train0, y_test= train_test_split(\n",
    "    california_housing[\"data\"],\n",
    "    california_housing[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49dd77cf-d2f2-4276-9845-54d98b50f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_validation, y_train1, y_validation= train_test_split(X_train0,y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c660bce-fdc7-4da3-8e8d-c36c058d4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "X_train_s= sc.fit_transform(X_train1)\n",
    "X_validation_s= sc.transform(X_validation)\n",
    "X_test_s= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe181f3-2459-45b9-91f1-26c8b5a3cb8f",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f53c3c-56ac-4763-99db-5ec4bf2f3be4",
   "metadata": {},
   "source": [
    "#### First we define the input layer of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8cc3bc-5a97-4e90-999c-1b9f4c698cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_= keras.layers.Input(shape= X_train1.shape[1:]) # the input function has the shape attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a55a8-066e-4541-bfd6-71a508efeba5",
   "metadata": {},
   "source": [
    "##### The shape attribute the dimensionality (features) of each datapoint within the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b9d6e6-56f3-4a26-b4f1-9fa6c97a2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4c149-41a0-4842-afda-84f6f9648642",
   "metadata": {},
   "source": [
    "11610 is the num of samples and 8 is the dimensionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2294da8-3efb-4ffc-9dee-41d483462652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4f31e-af51-417f-8e00-d21ec4cef7af",
   "metadata": {},
   "source": [
    "#### Defining the hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9affd9-a82c-412a-ab6b-c78ba89232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers1= keras.layers.Dense(50, activation= \"relu\")(input_)\n",
    "hidden_layers2= keras.layers.Dense(10, activation= \"relu\")(hidden_layers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4dbfa-e2c2-44ef-b10a-e8b5f99892fc",
   "metadata": {},
   "source": [
    "#### Defining the concatenate layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7516cc78-2405-45d8-af60-13eda8b4c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_layer= keras.layers.Concatenate()([input_, hidden_layers2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5dcd9f-30b0-43c6-a800-9ad5dbe1a5f9",
   "metadata": {},
   "source": [
    "#### Defining the output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eee3f896-48b9-41a3-a59c-d4d25ab2bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output= keras.layers.Dense(1)(concatenate_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153dc7f-b496-429f-89a8-fc1aed5ddade",
   "metadata": {},
   "source": [
    "#### Defining the model by connecting the layers together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be9a2295-2d49-4b5a-b64b-1091745daa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f= keras.Model(inputs= [input_], outputs= [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c5743-1ef3-4838-bb01-1fd15dc4a7d5",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af07df9e-a5da-48f2-90e3-bed331674ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.compile(loss= \"mean_squared_error\", # the objective function that will be optimized by sgd\n",
    "              optimizer= \"sgd\",\n",
    "              metrics= [\"mean_absolute_error\"]) # metric that is used to represent the degree of accuracy of the model (MAE is used instead of MSE since the MSE is dollar powered by 2 !!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443482c6-4704-4ef7-8afe-eb18d062e36c",
   "metadata": {},
   "source": [
    "## Fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51fd6bde-62b2-4275-b0ef-e14b86199a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "204/363 [===============>..............] - ETA: 0s - loss: 0.8937 - mean_absolute_error: 0.6648 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 00:57:45.523621: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 441us/step - loss: 1.2549 - mean_absolute_error: 0.6555 - val_loss: 0.6047 - val_mean_absolute_error: 0.5560\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 300us/step - loss: 1031.8739 - mean_absolute_error: 2.9139 - val_loss: 0.5689 - val_mean_absolute_error: 0.5590\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 305us/step - loss: 0.5504 - mean_absolute_error: 0.5457 - val_loss: 0.5900 - val_mean_absolute_error: 0.5427\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 315us/step - loss: 0.5359 - mean_absolute_error: 0.5345 - val_loss: 0.5289 - val_mean_absolute_error: 0.5378\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 312us/step - loss: 0.6866 - mean_absolute_error: 0.5385 - val_loss: 0.5506 - val_mean_absolute_error: 0.5339\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 299us/step - loss: 0.5355 - mean_absolute_error: 0.5338 - val_loss: 0.5491 - val_mean_absolute_error: 0.5317\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5353 - mean_absolute_error: 0.5330 - val_loss: 0.5423 - val_mean_absolute_error: 0.5350\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 298us/step - loss: 0.5344 - mean_absolute_error: 0.5321 - val_loss: 0.5789 - val_mean_absolute_error: 0.5343\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 298us/step - loss: 0.5310 - mean_absolute_error: 0.5319 - val_loss: 0.5392 - val_mean_absolute_error: 0.5387\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5290 - mean_absolute_error: 0.5314 - val_loss: 0.5348 - val_mean_absolute_error: 0.5348\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5340 - mean_absolute_error: 0.5330 - val_loss: 0.5392 - val_mean_absolute_error: 0.5313\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5373 - mean_absolute_error: 0.5319 - val_loss: 0.5368 - val_mean_absolute_error: 0.5339\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5288 - mean_absolute_error: 0.5316 - val_loss: 0.5468 - val_mean_absolute_error: 0.5318\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 298us/step - loss: 0.5295 - mean_absolute_error: 0.5313 - val_loss: 0.5367 - val_mean_absolute_error: 0.5344\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 297us/step - loss: 0.5296 - mean_absolute_error: 0.5321 - val_loss: 0.5491 - val_mean_absolute_error: 0.5353\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 299us/step - loss: 0.5297 - mean_absolute_error: 0.5313 - val_loss: 0.6552 - val_mean_absolute_error: 0.5395\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 304us/step - loss: 0.5332 - mean_absolute_error: 0.5315 - val_loss: 0.5374 - val_mean_absolute_error: 0.5317\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 303us/step - loss: 0.5346 - mean_absolute_error: 0.5308 - val_loss: 0.5374 - val_mean_absolute_error: 0.5364\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 299us/step - loss: 0.5378 - mean_absolute_error: 0.5313 - val_loss: 0.5421 - val_mean_absolute_error: 0.5405\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 299us/step - loss: 0.5468 - mean_absolute_error: 0.5332 - val_loss: 0.5381 - val_mean_absolute_error: 0.5287\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 309us/step - loss: 0.6908 - mean_absolute_error: 0.5384 - val_loss: 0.5384 - val_mean_absolute_error: 0.5368\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 312us/step - loss: 0.5336 - mean_absolute_error: 0.5329 - val_loss: 0.5409 - val_mean_absolute_error: 0.5371\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 315us/step - loss: 0.5310 - mean_absolute_error: 0.5323 - val_loss: 0.5548 - val_mean_absolute_error: 0.5352\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 313us/step - loss: 0.5309 - mean_absolute_error: 0.5317 - val_loss: 0.5562 - val_mean_absolute_error: 0.5351\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 313us/step - loss: 0.5320 - mean_absolute_error: 0.5329 - val_loss: 0.5394 - val_mean_absolute_error: 0.5310\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 305us/step - loss: 0.5335 - mean_absolute_error: 0.5314 - val_loss: 0.5374 - val_mean_absolute_error: 0.5346\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 310us/step - loss: 0.5441 - mean_absolute_error: 0.5341 - val_loss: 0.5439 - val_mean_absolute_error: 0.5323\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 314us/step - loss: 0.5442 - mean_absolute_error: 0.5337 - val_loss: 0.5447 - val_mean_absolute_error: 0.5354\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 309us/step - loss: 0.5272 - mean_absolute_error: 0.5313 - val_loss: 0.5308 - val_mean_absolute_error: 0.5289\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 304us/step - loss: 0.7088 - mean_absolute_error: 0.5433 - val_loss: 0.5368 - val_mean_absolute_error: 0.5308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28267e910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f.fit(X_train_s, y_train1, epochs= 30,\n",
    "          validation_data= (X_validation_s,y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f193bc-77c7-43b9-899d-62629404195f",
   "metadata": {},
   "source": [
    "# Wide and deep models with two input sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3c307-74f3-41c6-9f12-b26afc901a6b",
   "metadata": {},
   "source": [
    "Another posibility could be seperating our input into two sections, giving one section to the hidden layer 1 and the other section directly to the concatenate layer. \n",
    "\n",
    "\n",
    "Let's say our dataframe has 8 features. The way we seperate the input is that for example one section contains all samples but only has the values for the first 5 features and the other section has all samples but only has the values for the last three features. \n",
    "\n",
    "\n",
    "It is also important to note that it is possible to have sections of input that have overlapping features. For example, section one has the values for the feature 1 to feature 4 and section two is feature 2 to feature 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d929383-5626-4f88-8620-2b53d2aede48",
   "metadata": {},
   "source": [
    "### Preprocessing step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5ac59c1-594b-4ae4-be65-1145e1c13bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing= fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "799247b1-3ca3-4ac1-88b6-260dfc53caa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4af40852-4b82-4ee3-be80-c3562645c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0,X_test, y_train0, y_test= train_test_split(\n",
    "    california_housing[\"data\"],\n",
    "    california_housing[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aa3849d-efe6-4cae-bc3a-558a541e4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_validation, y_train1, y_validation= train_test_split(X_train0,y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "459f16cb-4bda-4add-acf2-86e58409d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "X_train_s= sc.fit_transform(X_train1)\n",
    "X_validation_s= sc.transform(X_validation)\n",
    "X_test_s= sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8ba68-91f2-4879-8175-f15e91ac3775",
   "metadata": {},
   "source": [
    "### Seperating the dataset into two different sections (cause we have two inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50f62b31-a517-4d36-8782-1257d6b7f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s_1, X_train_s_2= X_train_s[:, :6], X_train_s[:, -4:]\n",
    "X_validation_s_1, X_validation_s_2= X_validation_s[:, :6], X_validation_s[:, -4:]\n",
    "X_test_s_1, X_test_s_2= X_test_s[:, :6], X_test_s[:, -4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d81e4-3d2a-4d1d-9648-47ee439c184e",
   "metadata": {},
   "source": [
    "### Defining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b486135-cc9b-471a-95ad-6044c8fcf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1= keras.layers.Input(shape= [6])\n",
    "input_2= keras.layers.Input(shape= [4])\n",
    "hidden_layers1= keras.layers.Dense(50, activation= \"relu\")(input_1)\n",
    "hidden_layers2= keras.layers.Dense(10, activation= \"relu\")(hidden_layers1)\n",
    "concatenate_layer= keras.layers.Concatenate()([input_2, hidden_layers2])\n",
    "output= keras.layers.Dense(1)(concatenate_layer)\n",
    "model_f2= keras.Model(inputs= [input_1,input_2], outputs= [output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb51bba-d6e0-4804-9d0a-8c1797ea26f7",
   "metadata": {},
   "source": [
    "### Compiling the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f43961-7d9a-467d-94da-589795bbe743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f2.compile(loss= \"mean_squared_error\", # the objective function that will be optimized by sgd\n",
    "              optimizer= \"sgd\",\n",
    "              metrics= [\"mean_absolute_error\"]) # metric that is used to represent the degree of accuracy of the model (MAE is used instead of MSE since the MSE is dollar powered by 2 !!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9c655-f87b-4ca2-bca9-cb08157fd6e9",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b1ffdde-10f1-4217-bbd6-027a1679e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 433us/step - loss: 0.8644 - mean_absolute_error: 0.6380 - val_loss: 7.3953 - val_mean_absolute_error: 0.6102\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 318us/step - loss: 0.8112 - mean_absolute_error: 0.5376 - val_loss: 0.4759 - val_mean_absolute_error: 0.5207\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 316us/step - loss: 0.4739 - mean_absolute_error: 0.4985 - val_loss: 0.4506 - val_mean_absolute_error: 0.4918\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 316us/step - loss: 0.4724 - mean_absolute_error: 0.4810 - val_loss: 0.5552 - val_mean_absolute_error: 0.4935\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 314us/step - loss: 0.8345 - mean_absolute_error: 0.5182 - val_loss: 2.8009 - val_mean_absolute_error: 0.5168\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 314us/step - loss: 2.4925 - mean_absolute_error: 0.4983 - val_loss: 94.9179 - val_mean_absolute_error: 0.8860\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 316us/step - loss: 285.7659 - mean_absolute_error: 2.1045 - val_loss: 68.8597 - val_mean_absolute_error: 1.0231\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 315us/step - loss: 5202126511322169344.0000 - mean_absolute_error: 156538032.0000 - val_loss: 70566740492288.0000 - val_mean_absolute_error: 5634051.0000\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 316us/step - loss: 45202140037120.0000 - mean_absolute_error: 3961074.2500 - val_loss: 113507748020224.0000 - val_mean_absolute_error: 3124031.0000\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 319us/step - loss: 339480120655872.0000 - mean_absolute_error: 3385046.2500 - val_loss: 1994875809562624.0000 - val_mean_absolute_error: 3940043.2500\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 321us/step - loss: 6223636855783424.0000 - mean_absolute_error: 8432862.0000 - val_loss: 37492242700566528.0000 - val_mean_absolute_error: 14411510.0000\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 321us/step - loss: 32394466560049152.0000 - mean_absolute_error: 18314876.0000 - val_loss: 724167014075072512.0000 - val_mean_absolute_error: 68903768.0000\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 322us/step - loss: 669058048181927936.0000 - mean_absolute_error: 124687712.0000 - val_loss: 13733920577712816128.0000 - val_mean_absolute_error: 275836736.0000\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 320us/step - loss: 41313630444194889728.0000 - mean_absolute_error: 632085120.0000 - val_loss: 261647896943343435776.0000 - val_mean_absolute_error: 1207165184.0000\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 319us/step - loss: 243466759694532476928.0000 - mean_absolute_error: 2684670208.0000 - val_loss: 5032336860322581184512.0000 - val_mean_absolute_error: 5212786688.0000\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 317us/step - loss: 15569668991359811321856.0000 - mean_absolute_error: 14711092224.0000 - val_loss: 96049440188833684520960.0000 - val_mean_absolute_error: 23685072896.0000\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 320us/step - loss: 82735376552844249268224.0000 - mean_absolute_error: 25528948736.0000 - val_loss: 1856470523745340116434944.0000 - val_mean_absolute_error: 103804436480.0000\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 331us/step - loss: 1675626138836471616897024.0000 - mean_absolute_error: 208653647872.0000 - val_loss: 35479224701990985397174272.0000 - val_mean_absolute_error: 439442046976.0000\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 333us/step - loss: 110909010377958534185746432.0000 - mean_absolute_error: 961371111424.0000 - val_loss: 673601896891388345515507712.0000 - val_mean_absolute_error: 1921462697984.0000\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 335us/step - loss: 676462470388386633103704064.0000 - mean_absolute_error: 5297198333952.0000 - val_loss: 12820632343997486614710321152.0000 - val_mean_absolute_error: 8336115236864.0000\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 332us/step - loss: 41279437964415597790317510656.0000 - mean_absolute_error: 37869250936832.0000 - val_loss: 245427279628106083073007812608.0000 - val_mean_absolute_error: 36696087330816.0000\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 325us/step - loss: 759726915093423382375717404672.0000 - mean_absolute_error: 121452825149440.0000 - val_loss: 4701977344458934685349992988672.0000 - val_mean_absolute_error: 206580561739776.0000\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 331us/step - loss: 4964835596575018025092825219072.0000 - mean_absolute_error: 574973714366464.0000 - val_loss: 90108727004553366174701077921792.0000 - val_mean_absolute_error: 696203058610176.0000\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 331us/step - loss: 84499282187321816052964228333568.0000 - mean_absolute_error: 1435772402008064.0000 - val_loss: 1729716052681635087933763468918784.0000 - val_mean_absolute_error: 3039881752215552.0000\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 335us/step - loss: 1537426516894427148488613778423808.0000 - mean_absolute_error: 5534653771415552.0000 - val_loss: 33186278149429195950962806293004288.0000 - val_mean_absolute_error: 13550923540332544.0000\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 332us/step - loss: inf - mean_absolute_error: 58280928090259456.0000 - val_loss: inf - val_mean_absolute_error: 61640713502195712.0000\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 332us/step - loss: inf - mean_absolute_error: 89032730720862208.0000 - val_loss: inf - val_mean_absolute_error: 258931724166103040.0000\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 331us/step - loss: inf - mean_absolute_error: 431062262359261184.0000 - val_loss: inf - val_mean_absolute_error: 1151036048323641344.0000\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 323us/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan     \n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 330us/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2826f2040>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f2.fit((X_train_s_1, X_train_s_2), y_train1, epochs= 30,\n",
    "          validation_data= ((X_validation_s_1, X_validation_s_2),\n",
    "                            y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bf9b6-f713-421e-ba54-d5ca2626aff1",
   "metadata": {},
   "source": [
    "# Having deep and wide models with more than one output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61c78b-d81f-4a5e-8fd1-e868b71a235f",
   "metadata": {},
   "source": [
    "#### Useful for: \n",
    "\n",
    "        1- when having more than one output with different types ( one regression and one classification for example and the input is the same for example its just a picture \n",
    "\n",
    "        2- When having more than one output with the same type ( all is classification-based) \n",
    "\n",
    "        3- Helper out: having output for the hiiden layer(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d52ab0-fb9f-4639-b14b-4dab1e5165e9",
   "metadata": {},
   "source": [
    "### Â Lets say our model also has a Helper output as well as the main output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7c68058-ff57-47c2-b381-51e800c1c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1= keras.layers.Input(shape= [6])\n",
    "input_2= keras.layers.Input(shape= [4])\n",
    "hidden_layers1= keras.layers.Dense(50, activation= \"relu\")(input_1)\n",
    "hidden_layers2= keras.layers.Dense(10, activation= \"relu\")(hidden_layers1)\n",
    "concatenate_layer= keras.layers.Concatenate()([input_2, hidden_layers2])\n",
    "output= keras.layers.Dense(1, name= \"output\")(concatenate_layer)\n",
    "helper_output= keras.layers.Dense(1,name= \"helper_output\")(hidden_layers2)\n",
    "model_sub= keras.Model(inputs= [input_1,input_2],\n",
    "                   outputs= [output, helper_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a78a013-5096-48ae-becb-c23eec94111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub.compile(loss= [\"mean_squared_error\", \"mean_squared_error\"],#first one for the main output, second one for the helper output \n",
    "              loss_weights= [0.8, 0.2],\n",
    "              optimizer= \"sgd\",\n",
    "              metrics= [\"mean_absolute_error\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2fd4b-5922-42e0-9cb8-f41e1d710053",
   "metadata": {},
   "source": [
    "1- Note that one loss is also defined for the helper output. the value of the helper output will be compared to the actual y for each data point to see how the model has done so far by the end of that hidden layer \n",
    "\n",
    "2- Note that weights are given to each loss. sum of these weights should be one. It is basically saying that the loss of the helper output has only 20 percent of interaction in updating the weights of the neural network , whereas the loss of the main output has 80 percent interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57a8b2a8-023c-4948-9577-cb8478755d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.8120 - output_loss: 0.6905 - helper_output_loss: 1.2979 - output_mean_absolute_error: 0.5928 - helper_output_mean_absolute_error: 0.7910 - val_loss: 0.5440 - val_output_loss: 0.5240 - val_helper_output_loss: 0.6240 - val_output_mean_absolute_error: 0.5252 - val_helper_output_mean_absolute_error: 0.5871\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.4890 - output_loss: 0.4698 - helper_output_loss: 0.5660 - output_mean_absolute_error: 0.4917 - helper_output_mean_absolute_error: 0.5543 - val_loss: 0.5275 - val_output_loss: 0.5168 - val_helper_output_loss: 0.5705 - val_output_mean_absolute_error: 0.5014 - val_helper_output_mean_absolute_error: 0.5561\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 402us/step - loss: 1.1715 - output_loss: 1.3202 - helper_output_loss: 0.5765 - output_mean_absolute_error: 0.5424 - helper_output_mean_absolute_error: 0.5468 - val_loss: 1.1031 - val_output_loss: 1.2340 - val_helper_output_loss: 0.5796 - val_output_mean_absolute_error: 0.5213 - val_helper_output_mean_absolute_error: 0.5736\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 398us/step - loss: 2.8215 - output_loss: 3.1871 - helper_output_loss: 1.3595 - output_mean_absolute_error: 0.6114 - helper_output_mean_absolute_error: 0.8063 - val_loss: 0.6910 - val_output_loss: 0.5503 - val_helper_output_loss: 1.2537 - val_output_mean_absolute_error: 0.5447 - val_helper_output_mean_absolute_error: 0.7741\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 396us/step - loss: 1411297664.0000 - output_loss: 1763993344.0000 - helper_output_loss: 516641.5312 - output_mean_absolute_error: 3056.7080 - helper_output_mean_absolute_error: 38.7866 - val_loss: 273624.3750 - val_output_loss: 341964.5938 - val_helper_output_loss: 263.5893 - val_output_mean_absolute_error: 454.0211 - val_helper_output_mean_absolute_error: 16.0997\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 400us/step - loss: 97259.1953 - output_loss: 121552.3828 - helper_output_loss: 86.0313 - output_mean_absolute_error: 206.5352 - helper_output_mean_absolute_error: 8.5056 - val_loss: 30015.5449 - val_output_loss: 37514.8242 - val_helper_output_loss: 18.4756 - val_output_mean_absolute_error: 145.1520 - val_helper_output_mean_absolute_error: 3.7533\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 401us/step - loss: 22187.2285 - output_loss: 27732.5527 - helper_output_loss: 5.9400 - output_mean_absolute_error: 119.3835 - helper_output_mean_absolute_error: 2.1479 - val_loss: 12161.7881 - val_output_loss: 15200.9512 - val_helper_output_loss: 5.1468 - val_output_mean_absolute_error: 93.0421 - val_helper_output_mean_absolute_error: 1.2985\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 402us/step - loss: 8482.3457 - output_loss: 10602.5410 - helper_output_loss: 1.5709 - output_mean_absolute_error: 76.4581 - helper_output_mean_absolute_error: 1.0653 - val_loss: 5086.9829 - val_output_loss: 6357.6226 - val_helper_output_loss: 4.4274 - val_output_mean_absolute_error: 59.9090 - val_helper_output_mean_absolute_error: 0.9893\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 404us/step - loss: 3582.9819 - output_loss: 4478.3921 - helper_output_loss: 1.3323 - output_mean_absolute_error: 49.0469 - helper_output_mean_absolute_error: 0.9296 - val_loss: 2092.4460 - val_output_loss: 2614.4607 - val_helper_output_loss: 4.3900 - val_output_mean_absolute_error: 38.4475 - val_helper_output_mean_absolute_error: 0.9514\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 403us/step - loss: 1653.3708 - output_loss: 2066.3845 - helper_output_loss: 1.3192 - output_mean_absolute_error: 31.7103 - helper_output_mean_absolute_error: 0.9098 - val_loss: 881.7202 - val_output_loss: 1101.0532 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 24.8137 - val_helper_output_mean_absolute_error: 0.9451\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 403us/step - loss: 599.3589 - output_loss: 748.8691 - helper_output_loss: 1.3184 - output_mean_absolute_error: 20.2934 - helper_output_mean_absolute_error: 0.9063 - val_loss: 378.1492 - val_output_loss: 471.5894 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 16.1651 - val_helper_output_mean_absolute_error: 0.9435\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 439us/step - loss: 316.0276 - output_loss: 394.7049 - helper_output_loss: 1.3183 - output_mean_absolute_error: 13.2556 - helper_output_mean_absolute_error: 0.9052 - val_loss: 173.8291 - val_output_loss: 216.1893 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 10.4119 - val_helper_output_mean_absolute_error: 0.9434\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 445us/step - loss: 103.9480 - output_loss: 129.6053 - helper_output_loss: 1.3183 - output_mean_absolute_error: 8.4885 - helper_output_mean_absolute_error: 0.9050 - val_loss: 84.6019 - val_output_loss: 104.6553 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 6.8672 - val_helper_output_mean_absolute_error: 0.9435\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 429us/step - loss: 60.2099 - output_loss: 74.9329 - helper_output_loss: 1.3183 - output_mean_absolute_error: 5.6017 - helper_output_mean_absolute_error: 0.9058 - val_loss: 51.2344 - val_output_loss: 62.9459 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 4.4835 - val_helper_output_mean_absolute_error: 0.9425\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 400us/step - loss: 20.2632 - output_loss: 24.9994 - helper_output_loss: 1.3182 - output_mean_absolute_error: 3.6749 - helper_output_mean_absolute_error: 0.9043 - val_loss: 35.5860 - val_output_loss: 43.3854 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 2.9579 - val_helper_output_mean_absolute_error: 0.9434\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 402us/step - loss: 8.4632 - output_loss: 10.2494 - helper_output_loss: 1.3183 - output_mean_absolute_error: 2.4229 - helper_output_mean_absolute_error: 0.9052 - val_loss: 29.4766 - val_output_loss: 35.7486 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 2.0529 - val_helper_output_mean_absolute_error: 0.9432\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 403us/step - loss: 4.1495 - output_loss: 4.8573 - helper_output_loss: 1.3183 - output_mean_absolute_error: 1.7003 - helper_output_mean_absolute_error: 0.9050 - val_loss: 26.8660 - val_output_loss: 32.4854 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 1.5092 - val_helper_output_mean_absolute_error: 0.9432\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 406us/step - loss: 2.3624 - output_loss: 2.6235 - helper_output_loss: 1.3183 - output_mean_absolute_error: 1.2605 - helper_output_mean_absolute_error: 0.9049 - val_loss: 25.8156 - val_output_loss: 31.1725 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 1.1916 - val_helper_output_mean_absolute_error: 0.9434\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 403us/step - loss: 1.7460 - output_loss: 1.8529 - helper_output_loss: 1.3183 - output_mean_absolute_error: 1.0308 - helper_output_mean_absolute_error: 0.9059 - val_loss: 25.2061 - val_output_loss: 30.4105 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 1.0249 - val_helper_output_mean_absolute_error: 0.9424\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 424us/step - loss: 1.2623 - output_loss: 1.2484 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.8777 - helper_output_mean_absolute_error: 0.9054 - val_loss: 25.1063 - val_output_loss: 30.2857 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.9312 - val_helper_output_mean_absolute_error: 0.9420\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 450us/step - loss: 1.1588 - output_loss: 1.1189 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.8141 - helper_output_mean_absolute_error: 0.9048 - val_loss: 24.6488 - val_output_loss: 29.7139 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.9103 - val_helper_output_mean_absolute_error: 0.9423\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 450us/step - loss: 1.1082 - output_loss: 1.0556 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7897 - helper_output_mean_absolute_error: 0.9048 - val_loss: 24.8450 - val_output_loss: 29.9591 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8815 - val_helper_output_mean_absolute_error: 0.9425\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 444us/step - loss: 1.0901 - output_loss: 1.0330 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7767 - helper_output_mean_absolute_error: 0.9055 - val_loss: 24.5265 - val_output_loss: 29.5610 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8921 - val_helper_output_mean_absolute_error: 0.9420\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 442us/step - loss: 1.4103 - output_loss: 1.4333 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7520 - helper_output_mean_absolute_error: 0.9050 - val_loss: 24.9913 - val_output_loss: 30.1420 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8663 - val_helper_output_mean_absolute_error: 0.9420\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 415us/step - loss: 1.1539 - output_loss: 1.1128 - helper_output_loss: 1.3182 - output_mean_absolute_error: 0.7797 - helper_output_mean_absolute_error: 0.9054 - val_loss: 24.8970 - val_output_loss: 30.0241 - val_helper_output_loss: 4.3887 - val_output_mean_absolute_error: 0.8646 - val_helper_output_mean_absolute_error: 0.9414\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 401us/step - loss: 1.0554 - output_loss: 0.9897 - helper_output_loss: 1.3182 - output_mean_absolute_error: 0.7620 - helper_output_mean_absolute_error: 0.9038 - val_loss: 25.0680 - val_output_loss: 30.2379 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8656 - val_helper_output_mean_absolute_error: 0.9429\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 398us/step - loss: 1.1717 - output_loss: 1.1351 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7818 - helper_output_mean_absolute_error: 0.9058 - val_loss: 24.9546 - val_output_loss: 30.0961 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8656 - val_helper_output_mean_absolute_error: 0.9420\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 448us/step - loss: 1.0751 - output_loss: 1.0143 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7709 - helper_output_mean_absolute_error: 0.9048 - val_loss: 24.9645 - val_output_loss: 30.1085 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8673 - val_helper_output_mean_absolute_error: 0.9423\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 442us/step - loss: 1.0635 - output_loss: 0.9997 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7666 - helper_output_mean_absolute_error: 0.9052 - val_loss: 24.8475 - val_output_loss: 29.9622 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8688 - val_helper_output_mean_absolute_error: 0.9422\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 437us/step - loss: 1.0650 - output_loss: 1.0017 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7686 - helper_output_mean_absolute_error: 0.9053 - val_loss: 24.8681 - val_output_loss: 29.9881 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8686 - val_helper_output_mean_absolute_error: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282790a00>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sub.fit((X_train_s_1, X_train_s_2), (y_train1, y_train1), epochs=30,  # for the main output and the helper output we use y_train1 as the actual values\n",
    "          validation_data=((X_validation_s_1, X_validation_s_2),\n",
    "                           (y_validation, y_validation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e9545-e2f0-4cc5-a425-2d59f98a586e",
   "metadata": {},
   "source": [
    "# Model saving in Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5561b-a546-4ca9-a9ee-a5020d6c7475",
   "metadata": {},
   "source": [
    "### Saving model_f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2f9172d-30d6-4004-8f89-127be6b3772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           450         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           510         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 18)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            19          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 979\n",
      "Trainable params: 979\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fa4dc12-155e-413d-aac7-0e0aab1c450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.save(\"housing_reg_model_f.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64f9e9-f76c-4557-93a5-a6b478e2bf23",
   "metadata": {},
   "source": [
    "### Loading model_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "748e08ca-cd9d-4bb0-b0dc-39be2aeb5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f_reg = keras.models.load_model(\"housing_reg_model_f.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ae46549-1c87-41b2-a42a-3550d8f7aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           450         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           510         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 18)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            19          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 979\n",
      "Trainable params: 979\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_f_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce80d1-0f38-4c87-a1cf-d0c8aa613aae",
   "metadata": {},
   "source": [
    "### Saving model_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fb9a79d-3f0f-4cf0-be47-b86bb87ae206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           350         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 10)           510         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 14)           0           ['input_5[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            15          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " helper_output (Dense)          (None, 1)            11          ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 886\n",
      "Trainable params: 886\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa3e6368-a709-4953-8a06-68ad53f44434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub.save(\"housing_reg_model_sub.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88032c6f-cba4-4859-a390-3063a8aeae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub_reg = keras.models.load_model(\"housing_reg_model_sub.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17d0376c-da30-41f8-bf34-f0c8e2da3129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           350         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 10)           510         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 14)           0           ['input_5[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            15          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " helper_output (Dense)          (None, 1)            11          ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 886\n",
      "Trainable params: 886\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sub.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729a8e3-48c7-417a-a854-ce2a05b765a9",
   "metadata": {},
   "source": [
    "# Callback "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f5f5d-609c-4853-a1d2-ac492f645910",
   "metadata": {},
   "source": [
    "### Model checkpoint callback: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e440b-7ba5-4354-a830-4249177aed9a",
   "metadata": {},
   "source": [
    "A model checkpoint callback is a mechanism in machine learning, specifically in neural network training, that helps to save the model at certain points during training. This is especially useful for preventing loss of progress in the event of interruptions and for maintaining the best version of the model. Here's a detailed explanation:\n",
    "\n",
    "### What is a Model Checkpoint Callback?\n",
    "\n",
    "A model checkpoint callback saves the model (or weights) to a file at certain intervals, such as at the end of an epoch or after a certain number of steps. The primary purposes of using a model checkpoint callback are:\n",
    "\n",
    "1. **Preventing Loss of Progress**: If training is interrupted (e.g., due to hardware failure, power outage, or accidental termination), the model can be loaded from the last saved checkpoint and training can resume from that point.\n",
    "2. **Saving the Best Model**: During training, the callback can monitor a specific metric (e.g., validation loss or accuracy) and save the model only when it performs better on that metric. This ensures that the best-performing model, according to the chosen metric, is saved.\n",
    "3. **Periodic Saving**: Models can be saved periodically (e.g., every epoch) so that different stages of training can be analyzed or so that a recent state can be resumed in case of interruption."
   ]
  },
  {
   "cell_type": "raw",
   "id": "93602a2c-acbd-4d53-8aaa-937682a59ca3",
   "metadata": {},
   "source": [
    "keras.callbacks.ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2d1f1-b921-40ad-9d34-e2c4d4ca3d2a",
   "metadata": {},
   "source": [
    "The code you provided is an instance of the `ModelCheckpoint` callback in Keras, which is used to save the model during training. Here's a breakdown of each argument and its purpose:\n",
    "\n",
    "1. **`filepath`**:\n",
    "   - Specifies the path where the model file will be saved. The filename can contain placeholders such as `{epoch}` and `{val_loss:.2f}` to include the epoch number and validation loss in the filename.\n",
    "\n",
    "2. **`monitor=\"val_loss\"`**:\n",
    "   - The metric to monitor for saving the model. In this case, it is set to monitor the validation loss. You can change this to other metrics like \"val_accuracy\" or \"loss\".\n",
    "\n",
    "3. **`verbose=0`**:\n",
    "   - Controls the verbosity of the output. If set to 0, no messages are printed. If set to 1, a message is printed each time the model is saved.\n",
    "\n",
    "4. **`save_best_only=False`**:\n",
    "   - If set to `True`, the model will only be saved when the monitored metric has improved. If `False`, the model is saved at the end of every epoch regardless of the metric's improvement.\n",
    "\n",
    "5. **`save_weights_only=False`**:\n",
    "   - If set to `True`, only the model's weights will be saved (using `model.save_weights(filepath)`). If `False`, the entire model is saved (using `model.save(filepath)`), which includes the architecture, optimizer, and state.\n",
    "\n",
    "6. **`mode=\"auto\"`**:\n",
    "   - Specifies the mode for the monitoring metric. It can be \"auto\", \"min\", or \"max\". In \"auto\" mode, Keras will infer the mode from the name of the monitored metric (e.g., metrics ending in \"acc\" are inferred to be \"max\" mode, while metrics ending in \"loss\" are inferred to be \"min\" mode). \"min\" mode means the model will be saved when the monitored metric decreases, and \"max\" mode means the model will be saved when the monitored metric increases.\n",
    "\n",
    "7. **`save_freq=\"epoch\"`**:\n",
    "   - Specifies when to save the model. The default value \"epoch\" means the model is saved at the end of every epoch. You can also set this to an integer value, which represents the number of samples between saves (e.g., `save_freq=1000` saves the model every 1000 samples).\n",
    "\n",
    "8. **`initial_value_threshold=None`**:\n",
    "   - Used to specify the initial value threshold for the monitored metric. If the monitored metric is above or below this threshold, the model will be saved. This is rarely used and is typically set to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb0d33-15cc-4f0e-8059-f144fd658f7d",
   "metadata": {},
   "source": [
    "### Using callback checkpoint for our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea3d4044-85d4-44b3-9e7c-2dae2c662bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback= keras.callbacks.ModelCheckpoint(\"model_cb_reg_housing.h5\",\n",
    "                                                          save_best_only= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62389d-5794-4e23-8716-82e0b2e75361",
   "metadata": {},
   "source": [
    "**`\"model_cb_reg_housing.h5\"`**:\n",
    "   - This is the `filepath` parameter. It specifies the path and filename where the model will be saved. In this case, the model will be saved as a file named `model_cb_reg_housing.h5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ca9b9e4-a0da-4242-a60e-a6b599dbfeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 480us/step - loss: 1.0713 - output_loss: 1.0095 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7711 - helper_output_mean_absolute_error: 0.9051 - val_loss: 24.8786 - val_output_loss: 30.0011 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8671 - val_helper_output_mean_absolute_error: 0.9418\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 412us/step - loss: 1.0765 - output_loss: 1.0161 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7676 - helper_output_mean_absolute_error: 0.9046 - val_loss: 24.4144 - val_output_loss: 29.4208 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8954 - val_helper_output_mean_absolute_error: 0.9424\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 402us/step - loss: 1.6211 - output_loss: 1.6969 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7724 - helper_output_mean_absolute_error: 0.9050 - val_loss: 25.0736 - val_output_loss: 30.2449 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8646 - val_helper_output_mean_absolute_error: 0.9423\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 408us/step - loss: 1.2421 - output_loss: 1.2231 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7883 - helper_output_mean_absolute_error: 0.9046 - val_loss: 24.8672 - val_output_loss: 29.9869 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8723 - val_helper_output_mean_absolute_error: 0.9429\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 407us/step - loss: 1.0500 - output_loss: 0.9830 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7619 - helper_output_mean_absolute_error: 0.9051 - val_loss: 25.1181 - val_output_loss: 30.3005 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8608 - val_helper_output_mean_absolute_error: 0.9429\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 407us/step - loss: 1.0650 - output_loss: 1.0017 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7567 - helper_output_mean_absolute_error: 0.9047 - val_loss: 24.9555 - val_output_loss: 30.0972 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8696 - val_helper_output_mean_absolute_error: 0.9434\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 412us/step - loss: 1.0820 - output_loss: 1.0229 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7727 - helper_output_mean_absolute_error: 0.9056 - val_loss: 24.9554 - val_output_loss: 30.0971 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8689 - val_helper_output_mean_absolute_error: 0.9428\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 421us/step - loss: 1.0832 - output_loss: 1.0245 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7692 - helper_output_mean_absolute_error: 0.9055 - val_loss: 24.3543 - val_output_loss: 29.3458 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.9014 - val_helper_output_mean_absolute_error: 0.9423\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 409us/step - loss: 1.3174 - output_loss: 1.3172 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7893 - helper_output_mean_absolute_error: 0.9047 - val_loss: 24.9243 - val_output_loss: 30.0582 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8678 - val_helper_output_mean_absolute_error: 0.9427\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 414us/step - loss: 1.0609 - output_loss: 0.9965 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7672 - helper_output_mean_absolute_error: 0.9054 - val_loss: 24.9408 - val_output_loss: 30.0789 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8644 - val_helper_output_mean_absolute_error: 0.9422\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 409us/step - loss: 1.1262 - output_loss: 1.0782 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7784 - helper_output_mean_absolute_error: 0.9048 - val_loss: 24.8488 - val_output_loss: 29.9638 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8732 - val_helper_output_mean_absolute_error: 0.9425\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 419us/step - loss: 1.0685 - output_loss: 1.0061 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7679 - helper_output_mean_absolute_error: 0.9047 - val_loss: 24.5556 - val_output_loss: 29.5974 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8869 - val_helper_output_mean_absolute_error: 0.9429\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 434us/step - loss: 1.3205 - output_loss: 1.3210 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7500 - helper_output_mean_absolute_error: 0.9049 - val_loss: 24.9642 - val_output_loss: 30.1081 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8677 - val_helper_output_mean_absolute_error: 0.9430\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 450us/step - loss: 1.0884 - output_loss: 1.0310 - helper_output_loss: 1.3182 - output_mean_absolute_error: 0.7667 - helper_output_mean_absolute_error: 0.9057 - val_loss: 25.0331 - val_output_loss: 30.1943 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8647 - val_helper_output_mean_absolute_error: 0.9421\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 436us/step - loss: 1.0645 - output_loss: 1.0011 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7653 - helper_output_mean_absolute_error: 0.9046 - val_loss: 24.8806 - val_output_loss: 30.0036 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8703 - val_helper_output_mean_absolute_error: 0.9426\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 426us/step - loss: 1.0762 - output_loss: 1.0157 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7716 - helper_output_mean_absolute_error: 0.9050 - val_loss: 24.9043 - val_output_loss: 30.0333 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8685 - val_helper_output_mean_absolute_error: 0.9426\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 407us/step - loss: 1.0564 - output_loss: 0.9909 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7649 - helper_output_mean_absolute_error: 0.9046 - val_loss: 25.0481 - val_output_loss: 30.2130 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8638 - val_helper_output_mean_absolute_error: 0.9432\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 404us/step - loss: 1.1411 - output_loss: 1.0968 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7802 - helper_output_mean_absolute_error: 0.9058 - val_loss: 24.9500 - val_output_loss: 30.0904 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8684 - val_helper_output_mean_absolute_error: 0.9422\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 404us/step - loss: 1.0660 - output_loss: 1.0029 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7679 - helper_output_mean_absolute_error: 0.9045 - val_loss: 25.0318 - val_output_loss: 30.1927 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8633 - val_helper_output_mean_absolute_error: 0.9429\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 431us/step - loss: 1.1112 - output_loss: 1.0594 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7814 - helper_output_mean_absolute_error: 0.9047 - val_loss: 24.9047 - val_output_loss: 30.0338 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8712 - val_helper_output_mean_absolute_error: 0.9433\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 459us/step - loss: 1.0569 - output_loss: 0.9915 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7633 - helper_output_mean_absolute_error: 0.9050 - val_loss: 24.9889 - val_output_loss: 30.1391 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8683 - val_helper_output_mean_absolute_error: 0.9433\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 452us/step - loss: 1.0630 - output_loss: 0.9992 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7623 - helper_output_mean_absolute_error: 0.9046 - val_loss: 24.7107 - val_output_loss: 29.7913 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8839 - val_helper_output_mean_absolute_error: 0.9439\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 455us/step - loss: 1.0625 - output_loss: 0.9985 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7685 - helper_output_mean_absolute_error: 0.9054 - val_loss: 24.9554 - val_output_loss: 30.0971 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8694 - val_helper_output_mean_absolute_error: 0.9434\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 442us/step - loss: 1.0656 - output_loss: 1.0025 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7694 - helper_output_mean_absolute_error: 0.9052 - val_loss: 24.8757 - val_output_loss: 29.9975 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8704 - val_helper_output_mean_absolute_error: 0.9431\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 460us/step - loss: 1.0575 - output_loss: 0.9923 - helper_output_loss: 1.3182 - output_mean_absolute_error: 0.7663 - helper_output_mean_absolute_error: 0.9062 - val_loss: 24.9821 - val_output_loss: 30.1305 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8623 - val_helper_output_mean_absolute_error: 0.9417\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 456us/step - loss: 1.1587 - output_loss: 1.1188 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7690 - helper_output_mean_absolute_error: 0.9049 - val_loss: 24.9400 - val_output_loss: 30.0778 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8670 - val_helper_output_mean_absolute_error: 0.9419\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 436us/step - loss: 1.0650 - output_loss: 1.0017 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7687 - helper_output_mean_absolute_error: 0.9043 - val_loss: 24.8867 - val_output_loss: 30.0112 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8692 - val_helper_output_mean_absolute_error: 0.9428\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 461us/step - loss: 1.0580 - output_loss: 0.9929 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7646 - helper_output_mean_absolute_error: 0.9044 - val_loss: 24.9496 - val_output_loss: 30.0898 - val_helper_output_loss: 4.3884 - val_output_mean_absolute_error: 0.8675 - val_helper_output_mean_absolute_error: 0.9436\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 461us/step - loss: 1.1476 - output_loss: 1.1049 - helper_output_loss: 1.3183 - output_mean_absolute_error: 0.7689 - helper_output_mean_absolute_error: 0.9060 - val_loss: 24.9319 - val_output_loss: 30.0678 - val_helper_output_loss: 4.3885 - val_output_mean_absolute_error: 0.8684 - val_helper_output_mean_absolute_error: 0.9424\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 458us/step - loss: 1.0597 - output_loss: 0.9950 - helper_output_loss: 1.3182 - output_mean_absolute_error: 0.7645 - helper_output_mean_absolute_error: 0.9055 - val_loss: 24.9003 - val_output_loss: 30.0282 - val_helper_output_loss: 4.3886 - val_output_mean_absolute_error: 0.8659 - val_helper_output_mean_absolute_error: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282796e20>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sub.fit((X_train_s_1, X_train_s_2), (y_train1, y_train1), epochs=30,\n",
    "          validation_data=((X_validation_s_1, X_validation_s_2),\n",
    "                           (y_validation, y_validation)),\n",
    "             callbacks= [model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127cddc-8373-4df7-bfbf-ea53067ff46d",
   "metadata": {},
   "source": [
    "**`callbacks=[model_checkpoint_callback]`**:\n",
    "   - This specifies the list of callback functions to be used during training. In this case, it includes `model_checkpoint_callback`, which is a `ModelCheckpoint` callback that saves the model during training under certain conditions.\n",
    "\n",
    "\n",
    "Let's consider an example where you train a model to predict housing prices. The model takes two sets of features: one related to the location and another related to the property characteristics. During training, the `ModelCheckpoint` callback saves the model to `model_cb_reg_housing.h5` every time the validation loss decreases. After 30 epochs, you will have the best version of your model saved, which you can then use for making predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317acd3-0bd9-437a-8703-38ba7c371388",
   "metadata": {},
   "source": [
    "## EarlyStopping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f688e1d1-11ad-46fc-9a57-520d6650f042",
   "metadata": {},
   "source": [
    "Early stopping is a powerful technique in Keras (and other machine learning frameworks) used to prevent overfitting and improve the generalization of your models. The EarlyStopping callback monitors a specific metric during training and stops the training process if the metric does not improve for a specified number of epochs, which is called the \"patience\" parameter. Hereâs a detailed explanation:\n",
    "\n",
    "### Key Concepts of EarlyStopping Callback\n",
    "\n",
    "1. **Monitoring Metric**: \n",
    "   - The metric you want to monitor (e.g., validation loss, validation accuracy) is specified using the `monitor` parameter.\n",
    "   - Commonly monitored metrics are `val_loss` (validation loss) and `val_accuracy` (validation accuracy).\n",
    "\n",
    "2. **Patience**:\n",
    "   - This parameter defines the number of epochs with no improvement after which training will be stopped.\n",
    "   - For example, if `patience=5`, training will stop if there is no improvement in the monitored metric for 5 consecutive epochs.\n",
    "\n",
    "3. **Mode**:\n",
    "   - The `mode` parameter can be set to `'min'`, `'max'`, or `'auto'`.\n",
    "   - `'min'` is used when the monitored metric should decrease (e.g., loss).\n",
    "   - `'max'` is used when the monitored metric should increase (e.g., accuracy).\n",
    "   - `'auto'` infers the mode from the name of the monitored metric.\n",
    "\n",
    "4. **Restore Best Weights**:\n",
    "   - When `restore_best_weights=True`, the model weights will be restored to the state of the best epoch before stopping the training. This is useful to ensure that the model has the best weights when training stops.\n",
    "\n",
    "### Example Code\n",
    "\n",
    "Here is a simple example of how to use the EarlyStopping callback in a Keras model:\n",
    "\n",
    "```python\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=5,            # Number of epochs to wait before stopping\n",
    "    mode='min',            # 'min' because we want to minimize validation loss\n",
    "    restore_best_weights=True  # Restore best weights\n",
    ")\n",
    "```\n",
    "\n",
    "### How It Works\n",
    "\n",
    "- **Training Phase**: The model is trained on the training data, and after each epoch, the validation loss (or other monitored metric) is evaluated.\n",
    "- **Monitoring Phase**: The EarlyStopping callback checks if the monitored metric has improved compared to the best value seen so far.\n",
    "- **Patience Check**: If there is no improvement for a number of epochs equal to the `patience` parameter, training stops.\n",
    "- **Best Weights Restoration**: If `restore_best_weights=True` is set, the model weights are reverted to those corresponding to the best value of the monitored metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534c426-5ff2-446f-aa1d-4122a6bb40bf",
   "metadata": {},
   "source": [
    "### Using EarlyStopping and checkpoint callback as two callbacks for our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4074b32d-13b4-4285-ade8-da0309f52fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback= keras.callbacks.ModelCheckpoint(\"model_cb_reg_housing.h5\",\n",
    "                                                          save_best_only= True)\n",
    "\n",
    "earlystopping_callback= keras.callbacks.EarlyStopping(patience= 5,\n",
    "                                                      restore_best_weights= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7ad2a1b-ecb7-4ff8-add3-f55685950575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "363/363 [==============================] - 0s 452us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 2/200\n",
      "363/363 [==============================] - 0s 391us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 3/200\n",
      "363/363 [==============================] - 0s 387us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 4/200\n",
      "363/363 [==============================] - 0s 386us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 5/200\n",
      "363/363 [==============================] - 0s 388us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282c341f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sub.fit((X_train_s_1, X_train_s_2), (y_train1, y_train1), epochs=200,\n",
    "          validation_data=((X_validation_s_1, X_validation_s_2),\n",
    "                           (y_validation, y_validation)),\n",
    "             callbacks= [model_checkpoint_callback, earlystopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0517a81-cb07-4bbd-a640-dea807af985c",
   "metadata": {},
   "source": [
    "## AS YOU CAN SEE, THE TRAINING HAS STOPPED AT EPOCH NUMBER 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0f3b5-1d38-472c-902f-068758fe8203",
   "metadata": {},
   "source": [
    "1. **ModelCheckpoint**:\n",
    "   - At the end of each epoch, the `ModelCheckpoint` callback checks if the monitored metric (by default, validation loss) has improved.\n",
    "   - If `save_best_only=True` and the metric has improved, the model is saved to `\"model_cb_reg_housing.h5\"`.\n",
    "\n",
    "2. **EarlyStopping**:\n",
    "   - After each epoch, the `EarlyStopping` callback checks the monitored metric (by default, validation loss).\n",
    "   - If the metric does not improve for 5 consecutive epochs (patience=5), training stops.\n",
    "   - If `restore_best_weights=True`, the model weights are reverted to the best epoch where the monitored metric was the best.\n",
    "\n",
    "\n",
    "Combining these two callbacks allows for efficient and effective model training:\n",
    "- **ModelCheckpoint** ensures you save the best version of your model during training.\n",
    "- **EarlyStopping** prevents unnecessary training epochs once the model stops improving, thus preventing overfitting and saving computational resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9378ad7-4617-44d3-a6f0-4c6935302b03",
   "metadata": {},
   "source": [
    "## Creating a personal callback method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708f06e-3292-4c1e-97f3-6edb7dc6fec9",
   "metadata": {},
   "source": [
    "Engineers sometimes define their own callback methods in Keras or other deep learning frameworks for several reasons:\n",
    "\n",
    "### 1. **Custom Requirements**:\n",
    "   - **Specialized Monitoring**: Built-in callbacks may not support all the metrics or conditions that a specific project requires. Engineers can create custom callbacks to monitor and respond to custom metrics or specific intermediate results.\n",
    "   - **Complex Conditions**: Projects might require more complex conditions for stopping training or saving models than what is provided by default. For instance, stopping training based on multiple conditions or a combination of metrics.\n",
    "\n",
    "### 2. **Advanced Logging and Visualization**:\n",
    "   - **Custom Logging**: Custom callbacks can be used to log additional information during training, such as specific layer outputs, gradients, or other intermediate values that are not tracked by default.\n",
    "   - **Real-time Visualization**: Engineers might want to create custom visualizations, like plotting dynamic learning curves, visualizing activation maps, or other custom plots, during training.\n",
    "\n",
    "### 3. **Automated Actions**:\n",
    "   - **Adaptive Learning Rate**: While Keras provides callbacks for learning rate scheduling, custom callbacks can implement more sophisticated adaptive learning rate strategies tailored to the specific needs of the training process.\n",
    "   - **Dynamic Architecture Adjustments**: In some cases, it may be beneficial to modify the model architecture dynamically during training (e.g., adding more neurons or layers based on performance metrics).\n",
    "\n",
    "### 4. **Integration with External Tools**:\n",
    "   - **Custom Notifications**: Engineers might need to integrate the training process with external systems, such as sending notifications or alerts (e.g., via email or messaging apps) when certain events occur during training.\n",
    "   - **External Resource Management**: Custom callbacks can help manage external resources, like saving intermediate results to a database, interacting with cloud storage, or handling distributed training setups.\n",
    "\n",
    "### 5. **Experimentation and Research**:\n",
    "   - **Research and Experimentation**: Researchers often experiment with new training techniques, regularization methods, or optimization strategies that are not yet available as built-in callbacks. Custom callbacks allow for quick prototyping and experimentation.\n",
    "   - **Hyperparameter Tuning**: Custom callbacks can be designed to modify hyperparameters on the fly based on intermediate training results, allowing for more dynamic and potentially more effective training processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf61dae5-2da7-4d94-b28d-223958fdb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_train_end(self,logs= None):\n",
    "        print(\"\")\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(logs[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14e0767b-e2b4-4eb5-afe4-054bac6bcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycb= MyCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf479d-ff8f-4556-932c-a5b3c4bd6347",
   "metadata": {},
   "source": [
    "### Method Details\n",
    "\n",
    "#### 1. `on_train_end(self, logs=None)`\n",
    "```python\n",
    "def on_train_end(self, logs=None):\n",
    "    print(\"\")\n",
    "```\n",
    "- **Purpose**: This method is called at the end of training.\n",
    "- **Logs**: The `logs` parameter is a dictionary containing information about the training process, such as the final training and validation metrics.\n",
    "- **Behavior**: In this implementation, it simply prints an empty string. This is a placeholder and can be modified to perform any action desired when the training ends.\n",
    "\n",
    "#### 2. `on_epoch_end(self, epoch, logs)`\n",
    "```python\n",
    "def on_epoch_end(self, epoch, logs):\n",
    "    print(logs[\"val_loss\"])\n",
    "```\n",
    "- **Purpose**: This method is called at the end of each epoch.\n",
    "- **Parameters**:\n",
    "  - `epoch`: The index of the epoch that has just ended.\n",
    "  - `logs`: A dictionary containing the logs for the epoch, including metrics like `val_loss`, `val_accuracy`, etc.\n",
    "- **Behavior**: This implementation prints the validation loss (`val_loss`) at the end of each epoch. The `logs` dictionary contains the values of metrics computed during the epoch.\n",
    "\n",
    "The `MyCallback` class is a simple example of creating a custom callback in Keras. It demonstrates how to extend the `keras.callbacks.Callback` class to monitor specific metrics and perform actions at specific points during the training process. This approach provides flexibility to meet unique requirements in model training and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adf4341d-7e1b-478e-942b-bc7de3cba2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "315/363 [=========================>....] - ETA: 0s - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nannan\n",
      "363/363 [==============================] - 0s 442us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 2/200\n",
      "344/363 [===========================>..] - ETA: 0s - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nannan\n",
      "363/363 [==============================] - 0s 389us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 3/200\n",
      "344/363 [===========================>..] - ETA: 0s - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nannan\n",
      "363/363 [==============================] - 0s 388us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 4/200\n",
      "344/363 [===========================>..] - ETA: 0s - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nannan\n",
      "363/363 [==============================] - 0s 390us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "Epoch 5/200\n",
      "344/363 [===========================>..] - ETA: 0s - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nannan\n",
      "363/363 [==============================] - 0s 389us/step - loss: nan - output_loss: nan - helper_output_loss: nan - output_mean_absolute_error: nan - helper_output_mean_absolute_error: nan - val_loss: nan - val_output_loss: nan - val_helper_output_loss: nan - val_output_mean_absolute_error: nan - val_helper_output_mean_absolute_error: nan\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283821430>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sub.fit((X_train_s_1, X_train_s_2), (y_train1, y_train1), epochs=200,\n",
    "          validation_data=((X_validation_s_1, X_validation_s_2),\n",
    "                           (y_validation, y_validation)),\n",
    "             callbacks= [model_checkpoint_callback, earlystopping_callback,mycb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
